
# -*- coding: utf-8 -*-
"""Lab2_Task1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wx5pK8x8CkuUmGAo16FfmplbV4err4GQ
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/gdrive')
# %cd /gdrive/My Drive/Big Data - lab_2

"""## **importing the libraries**"""

import numpy as np
import scipy.sparse as sp
import scipy.sparse.linalg
from matplotlib import pyplot as plt

filename = "verification"
nr_users = 2000
nr_movies = 1500

def load_data(name):
    data = np.genfromtxt(name,delimiter=',',dtype=int)
    data[:,0:2] -= 1
    return data

def getA(data):
    nr_ratings = len(data)

    r = np.concatenate((np.arange(nr_ratings,dtype=int), np.arange(nr_ratings,dtype=int)))
    c = np.concatenate((data[:,0], data[:,1]+nr_users))
    d = np.ones((2*nr_ratings,))

    A = sp.csr_matrix((d,(r,c)),shape=(nr_ratings,nr_users+nr_movies))

    return A

training_data = load_data(filename+'.training')
test_data = load_data(filename+'.test')

A = getA(training_data)

print(training_data.shape)
print(test_data.shape)
print(A.shape)

#print(A)
df = load_data(filename+'.training')
print(df.shape)
print(df)

import  numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.sparse.linalg import lsqr

"""## **Loading the Dateset**"""

#reading the file and extracting data to a dataframe
#df = pd.read_csv('saema095.training')  # or delimiter=';' or delimiter='|' etc.
##print(df.shape)
#df_plus = pd.read_csv('saema095.moviename', encoding='latin-1', delimiter='\t')

# unique function to find th number of movies
#print(f"the numer of unique movies in the 'm' column of the trainingset {np.unique(df.iloc[:,1])} ")

#print(f'the number of movies : {len(np.unique(df.iloc[:,1]))} ')
#print(' the movies are not in order...\n but just they have been labeled with numbers by the order that they had in dataset')

"""## **Adding the column with the name of the movies to the dataset**"""

#columns = ['user_id', 'movie_id', 'rating']
#df.columns = columns
#print(df.head())
#print(df_plus.head())
#print("\nthis an affilation netwrok, the 'enteties' are 'user_id's and 'groups' are 'movie_ids'")
#print('now we form the A matix')

#B = np.zeros((len(np.unique(df.iloc[:,0]))+1, len(np.unique(df.iloc[:,1]))+1))

#print(B.shape)

# out of bound index : 2000 so i changed the dimension to (2001 , 1501)
#max_user_id = df['user_id'].max()
#max_movie_id = df['movie_id'].max()
#print(max_user_id)
#print(max_movie_id)
#print(df.iloc[:,0])
#for idx, i  in enumerate(df.iloc[:,0]):
 # B[i, df['movie_id'][idx]] = df['rating'][idx]

#daghighan barabar shod ba oon chizi ke az print(df.head()) balatar tooye sotoone sevom gereftim
#print(B[0:30,1])


#print(B.shape)
##see if we have any rows or columns fully zero
#print(sum(B[0,:] != 0))

#now we drop them

#B = np.delete(B, 0, axis=0)
#B = np.delete(B, 0, axis=1)
#done!
#print(B.shape)

"""## **Now we have the cleaned B matrix**"""

#print(B)



#nr_users = 2000
#nr_movies = 1500
#print(np.mean(B))

#now i take the non-zero values:
#non_zero_B = B[B != 0]
#print(non_zero_B)

#print(np.mean(non_zero_B))
#now we got r_bar
#r_bar = np.mean(non_zero_B)
#print(f'r_bar is : {r_bar}')
#now we compute bu:

#aux_list = []
##we  enter the user that we want as u
#u = 1201
#aux_list_user = B[u , B[u,:] != 0]
#bu = np.sum(aux_list_user)/len(aux_list_user) - r_bar
#print(f'bu is : {bu}')

#now we compute the bi for movies :
#aux_list_movie =[]
#i = 953
#aux_list_movie = B[B[:,i] != 0 , i ]
#bi = np.sum(aux_list_movie)/len(aux_list_movie) - r_bar
#print(f'bi is : {bi}')

##finally :
#r_hat_ui = r_bar + bu + bi
#print(f'r_hat_ui is : {r_hat_ui}')

r_bar = np.mean(df[:,2])


c = df[:,2] - r_bar

solution =lsqr(A,c)
b = solution[0]
print(len(b))
bU = b[:nr_users]
bM = b[nr_users:]
print(len(bU))
print(len(bM))
r_hat=A*b +r_bar
print(bU)
print(r_hat)

"""## **now i writethe functions of it in the final code**"""

nr_users = 2000
nr_movies = 1500


def train_baseline(training_data):
    """
    Uses the provided dataset to train the baseline predictor.
    Should return three things:
    r_bar: the average rating over all users and movies
    bu: vector where the i:th entry represents the bias of the i:th user compared to r_bar
    bm: vector where the i:th entry represents the bias of the i:th movie compared to r_bar
    """
    r_bar = np.mean(training_data[:,2])
    c = training_data[:,2] - r_bar
    A = getA(training_data)
    solution =lsqr(A,c)
    b = solution[0]
    bu = b[:nr_users]
    bm = b[nr_users:]


    return r_bar,bu, bm

def baseline_prediction(training_data,datasets_to_predict):
    """
    Uses the training_data to train the baseline predictor,
    then evaluates its performance on all the datasets in the test_datas list
    """
    r_bar,bu, bm = train_baseline(training_data)




    # Create a list with one element for each dataset in datasets_to_predict.
    # Each entry (r_hat) should be an array with the predicted ratings for all pairs of users and movies in that dataset
    r_hats = []
    r_reals = []
    for data in datasets_to_predict:
        r_hat = r_bar + bu[data[:, 0]] + bm[data[:, 1]]
        r_hat = np.clip(r_hat, 1, 5)
        r_real = data[:, 2]

        r_hats.append(r_hat)
        r_reals.append(r_real)


    return r_hats

"""## **one example to see:**"""

nr_users = 2000
nr_movies = 1500


def train_baseline(training_data):
    """
    Uses the provided dataset to train the baseline predictor.
    Should return three things:
    r_bar: the average rating over all users and movies
    bu: vector where the i:th entry represents the bias of the i:th user compared to r_bar
    bm: vector where the i:th entry represents the bias of the i:th movie compared to r_bar
    """
    r_bar = np.mean(training_data[:,2])
    c = training_data[:,2] - r_bar
    A = getA(training_data)
    solution =lsqr(A,c)
    b = solution[0]
    bu = b[:nr_users]
    bm = b[nr_users:]


    return r_bar,bu, bm


def baseline_prediction(training_data, datasets_to_predict):
    """
    Uses the training_data to train the baseline predictor,
    then evaluates its performance on all the datasets in the test_datas list
    """
    r_bar, bu, bm = train_baseline(training_data)

    r_hats = []
    r_reals = []

    # Wrap datasets_to_predict in a list if it's not already a list
    if not isinstance(datasets_to_predict, list):
        datasets_to_predict = [datasets_to_predict]  # This line has been modified

    for data in datasets_to_predict:
        r_hat = r_bar + bu[data[:, 0].astype(int)] + bm[data[:, 1].astype(int)] # This line has been modified
        r_hat = np.clip(r_hat, 1, 5)
        r_real = data[:, 2]

        r_hats.append(r_hat)
        r_reals.append(r_real)

    return r_hats , r_reals


###calculating rmses: for training set and test set:)

predicted, reals = baseline_prediction(training_data, training_data)
predicted = np.array(predicted) # Access the first element of the list since it is a list of one array
reals = np.array(reals) # Access the first element of the list since it is a list of one array
rmse = np.sqrt(np.mean((predicted - reals) ** 2))
print(f'rmse of the training data is : {rmse}')

predicted, reals = baseline_prediction(training_data, test_data)
# Convert the lists to NumPy arrays before calculating the RMSE
predicted = np.array(predicted) # Access the first element of the list since it is a list of one array
reals = np.array(reals) # Access the first element of the list since it is a list of one array
rmse = np.sqrt(np.mean((predicted - reals) ** 2))
print(f'rmse of the test data is : {rmse}')


predicted, reals = baseline_prediction(training_data, test_data)
# Convert the lists to NumPy arrays before calculating the RMSE
predicted = np.array(predicted) # Access the first element of the list since it is a list of one array
reals = np.array(reals) # Access the first element of the list since it is a list of one array
error = np.abs(predicted - reals)
predicted_rounded = np.clip(np.round(predicted), 1, 5)
print(predicted_rounded)
print(reals)
    # Compute the absolute errors
absolute_errors = np.abs(predicted_rounded - reals)

print(absolute_errors)

#plt.hist(absolute_errors)
# Flatten absolute_errors to a 1D array before sampling
sample_data = absolute_errors.flatten()
print(np.max( sample_data))
# Limit the number of bins
plt.hist(sample_data, bins=50)
plt.show()

"""task 2"""

predicted, reals = baseline_prediction(training_data, training_data)
print(len(predicted[0]))
predicted = np.concatenate(predicted)
reals = np.concatenate(reals)
print(len(predicted))
print(len(reals))
# mahze ehtiat bazam tabdil kardam be list be jaye [[]] va baz rmse ro hesab kardam
rmse = np.sqrt(np.mean((predicted - reals) ** 2))
print(rmse)

"""## **berim ba khial rahat soraghe task 2 ta hala concate kardam pred va reals ro:**"""

predicted, reals = baseline_prediction(training_data, training_data)
print(len(training_data))

predicted = np.concatenate(predicted)
reals = np.concatenate(reals)

r_tilde = reals - predicted
print(training_data.shape)

"""## **Task 2**"""

D = np.load('verification_D_mat.npy')
training_data = load_data(filename+'.training')
test_data = load_data(filename+'.test')
A = getA(training_data)
print(D.shape)
print(D[:5, :5])

u_min = 20
L = 100
    # Uncomment the following lines to check the correctness of the D matrix for u_min = 20 in the verification dataset
    # You should get an error that is less than 1e-5
    #
if filename == "verification" and u_min == 20:
error_in_D = np.linalg.norm(np.load('verification_D_mat.npy') - D)
print("Error in D matrix: {0:.5f}\n".format(error_in_D))

print(D)

import numpy as np

# Using your provided variables
nr_users = 2000
nr_movies = 1500

def train_baseline(training_data):
    """
    Baseline training as before.
    """
    r_bar = np.mean(training_data[:, 2])
    c = training_data[:, 2] - r_bar
    A = getA(training_data)
    solution = lsqr(A, c)
    b = solution[0]
    bu = b[:nr_users]
    bm = b[nr_users:]
    return r_bar, bu, bm

def baseline_prediction(training_data, datasets_to_predict):
    """
    Baseline prediction as before.
    """
    r_bar, bu, bm = train_baseline(training_data)
    r_hats, r_reals = [], []

    if not isinstance(datasets_to_predict, list):
        datasets_to_predict = [datasets_to_predict]

    for data in datasets_to_predict:
        r_hat = r_bar + bu[data[:, 0].astype(int)] + bm[data[:, 1].astype(int)]
        r_hat = np.clip(r_hat, 1, 5)
        r_real = data[:, 2]
        r_hats.append(r_hat)
        r_reals.append(r_real)

    return r_hats, r_reals

def improved_prediction(training_data, datasets_to_predict, D, L=200):
    """
    Improved prediction using neighborhood method with cosine similarity.
    """
    r_bar, bu, bm = train_baseline(training_data)
    r_hats, r_reals = [], []

    if not isinstance(datasets_to_predict, list):
        datasets_to_predict = [datasets_to_predict]

    for data in datasets_to_predict:
        r_hat = []
        for u, m, r in data:
            neighbors = np.argsort(-D[m])[:L]  # Get top-L similar movies to m
            numerator = sum(D[m, j] * (r_bar + bu[int(u)] + bm[int(j)] - r_bar )
                            for j in neighbors)
            denominator = sum(abs(D[m, j]) for j in neighbors)
            r_pred = r_bar + bu[int(u)] + bm[int(m)] + (numerator / denominator if denominator != 0 else 0)
            r_pred = np.clip(r_pred, 1, 5)
            r_hat.append(r_pred)
        r_hats.append(r_hat)
        r_reals.append(data[:, 2])

    return r_hats, r_reals

# Calculate RMSE for baseline and improved predictor
def calculate_rmse(predicted, real):
    predicted = np.concatenate(predicted)
    real = np.concatenate(real)
    return np.sqrt(np.mean((predicted - real) ** 2))

# Baseline RMSE
predicted_baseline, real_baseline = baseline_prediction(training_data, test_data)
rmse_baseline = calculate_rmse(predicted_baseline, real_baseline)
print("Baseline RMSE:", rmse_baseline)

# Improved RMSE
predicted_improved, real_improved = improved_prediction(training_data, test_data, D)
rmse_improved = calculate_rmse(predicted_improved, real_improved)
print("Improved RMSE:", rmse_improved)

# Report the improvement
improvement =  rmse_improved - rmse_baseline
print("Improvement in RMSE(percent):", improvement*100)

# Define the necessary variables and functions as before
nr_users = 2000
nr_movies = 1500

def train_baseline(training_data):
    r_bar = np.mean(training_data[:, 2])
    c = training_data[:, 2] - r_bar
    A = getA(training_data)  # Assumes getA is defined elsewhere
    solution = lsqr(A, c)
    b = solution[0]
    bu = b[:nr_users]
    bm = b[nr_users:]
    return r_bar, bu, bm

def baseline_prediction(training_data, datasets_to_predict):
    r_bar, bu, bm = train_baseline(training_data)
    r_hats, r_reals = [], []

    if not isinstance(datasets_to_predict, list):
        datasets_to_predict = [datasets_to_predict]

    for data in datasets_to_predict:
        r_hat = r_bar + bu[data[:, 0].astype(int)] + bm[data[:, 1].astype(int)]
        r_hat = np.clip(r_hat, 1, 5)
        r_real = data[:, 2]
        r_hats.append(r_hat)
        r_reals.append(r_real)

    return r_hats, r_reals

def improved_prediction(training_data, datasets_to_predict, D, L=1450):
    r_bar, bu, bm = train_baseline(training_data)
    r_hats, r_reals = [], []

    if not isinstance(datasets_to_predict, list):
        datasets_to_predict = [datasets_to_predict]

    for data in datasets_to_predict:
        r_hat = []
        for u, m, r in data:
            neighbors = np.argsort(-D[m])[:L]
            numerator = sum(D[m, j] * (r_bar + bu[int(u)] + bm[int(j)] - r_bar) for j in neighbors)
            denominator = sum(abs(D[m, j]) for j in neighbors)
            r_pred = r_bar + bu[int(u)] + bm[int(m)] + (numerator / denominator if denominator != 0 else 0)
            r_pred = np.clip(r_pred, 1, 5)
            r_hat.append(r_pred)
        r_hats.append(r_hat)
        r_reals.append(data[:, 2])

    return r_hats, r_reals

# Get absolute errors for baseline
predicted_baseline, real_baseline = baseline_prediction(training_data, test_data)
predicted_baseline = np.concatenate(predicted_baseline)
real_baseline = np.concatenate(real_baseline)
absolute_errors_baseline = np.abs(np.round(predicted_baseline) - real_baseline)

# Get absolute errors for improved predictor
D = np.random.rand(nr_movies, nr_movies)  # Assuming some D matrix is provided
predicted_improved, real_improved = improved_prediction(training_data, test_data, D)
###danger zone
rmse_improved = calculate_rmse(predicted_improved, real_improved)
print("Baseline RMSE:", rmse_improved)

predicted_baseline, real_baseline = baseline_prediction(training_data, test_data)
rmse_baseline = calculate_rmse(predicted_baseline, real_baseline)
print("Baseline RMSE:", rmse_baseline)
#####denager zone end
predicted_improved = np.concatenate(predicted_improved)

real_improved = np.concatenate(real_improved)
absolute_errors_improved = np.abs(np.round(predicted_improved) - real_improved)

# Plot the histograms
plt.figure(figsize=(10, 6))
bins = np.arange(0, 6) - 0.5  # Set bins from -0.5 to 4.5 for ratings from 1 to 5

plt.hist(absolute_errors_baseline, bins=bins, alpha=0.5, label='Baseline Absolute Error', color='blue', edgecolor='black')
plt.hist(absolute_errors_improved, bins=bins, alpha=0.5, label='Improved Absolute Error', color='green', edgecolor='black')

plt.xlabel('Absolute Error')
plt.ylabel('Frequency')
plt.title('Comparison of Absolute Errors: Baseline vs Improved Predictor')
plt.xticks(range(5))  # Set x-ticks to align with the error levels (0 to 4)
plt.legend()
plt.show()

rmse_improved = calculate_rmse(predicted_improved, real_improved)
print("Improved RMSE:", rmse_improved)

"""## **testtt**"""

import numpy as np

# Using your provided variables
nr_users = 2000
nr_movies = 1500

def train_baseline(training_data):
    """
    Baseline training as before.
    """
    r_bar = np.mean(training_data[:, 2])
    c = training_data[:, 2] - r_bar
    A = getA(training_data)
    solution = lsqr(A, c)
    b = solution[0]
    bu = b[:nr_users]
    bm = b[nr_users:]
    return r_bar, bu, bm

def baseline_prediction(training_data, datasets_to_predict):
    """
    Baseline prediction as before.
    """
    r_bar, bu, bm = train_baseline(training_data)
    r_hats, r_reals = [], []

    if not isinstance(datasets_to_predict, list):
        datasets_to_predict = [datasets_to_predict]

    for data in datasets_to_predict:
        r_hat = r_bar + bu[data[:, 0].astype(int)] + bm[data[:, 1].astype(int)]
        r_hat = np.clip(r_hat, 1, 5)
        r_real = data[:, 2]
        r_hats.append(r_hat)
        r_reals.append(r_real)

    return r_hats, r_reals

def improved_prediction(training_data, datasets_to_predict, D, L=1600):
    """
    Improved prediction using the neighborhood method with cosine similarity.
    """
    r_bar, bu, bm = train_baseline(training_data)
    r_hats, r_reals = [], []

    # Create a dictionary of user-movie ratings from the training data for fast lookup
    user_movie_ratings = {(int(u), int(m)): r for u, m, r in training_data}

    if not isinstance(datasets_to_predict, list):
        datasets_to_predict = [datasets_to_predict]

    for data in datasets_to_predict:
        r_hat = []
        for u, m, _ in data:
            u, m = int(u), int(m)
            # Baseline prediction
            r_hat_baseline = r_bar + bu[u] + bm[m]

            # Find top-L similar movies to m
            neighbors = np.argsort(-D[m])[:L]

            # Calculate the numerator and denominator for the improved prediction formula
            numerator = 0
            denominator = 0
            for j in neighbors:
                # Check if the user rated movie j
                if (u, j) in user_movie_ratings:
                    r_uj = user_movie_ratings[(u, j)]
                    r_hat_baseline_j = r_bar + bu[u] + bm[j]
                    numerator += D[m, j] * (r_uj - r_hat_baseline_j)
                    denominator += abs(D[m, j])

            # Final prediction
            if denominator != 0:
                r_hat_improved = r_hat_baseline + numerator / denominator
            else:
                r_hat_improved = r_hat_baseline

            # Clip the predicted rating to the valid range [1, 5]
            r_hat.append(np.clip(r_hat_improved, 1, 5))

        r_hats.append(r_hat)
        r_reals.append(data[:, 2])

    return r_hats, r_reals


# Calculate RMSE for baseline and improved predictor
def calculate_rmse(predicted, real):
    predicted = np.concatenate(predicted)
    real = np.concatenate(real)
    return np.sqrt(np.mean((predicted - real) ** 2))

# Baseline RMSE
predicted_baseline, real_baseline = baseline_prediction(training_data, test_data)
rmse_baseline = calculate_rmse(predicted_baseline, real_baseline)
print("Baseline RMSE:", rmse_baseline)

# Improved RMSE
predicted_improved, real_improved = improved_prediction(training_data, test_data, D)
rmse_improved = calculate_rmse(predicted_improved, real_improved)
print("Improved RMSE:", rmse_improved)

# Report the improvement
improvement =  rmse_baseline - rmse_improved
print("Improvement in RMSE(percent):", improvement*100)

# Get absolute errors for baseline
predicted_baseline, real_baseline = baseline_prediction(training_data, test_data)
predicted_baseline = np.concatenate(predicted_baseline)
real_baseline = np.concatenate(real_baseline)
absolute_errors_baseline = np.abs(np.round(predicted_baseline) - real_baseline)

# Get absolute errors for improved predictor
D = np.random.rand(nr_movies, nr_movies)  # Assuming some D matrix is provided
predicted_improved, real_improved = improved_prediction(training_data, test_data, D)
predicted_improved = np.concatenate(predicted_improved)
real_improved = np.concatenate(real_improved)
absolute_errors_improved = np.abs(np.round(predicted_improved) - real_improved)

# Plot the histograms
plt.figure(figsize=(10, 6))
bins = np.arange(0, 6) - 0.5  # Set bins from -0.5 to 4.5 for ratings from 1 to 5

plt.hist(absolute_errors_baseline, bins=bins, alpha=0.5, label='Baseline Absolute Error', color='blue', edgecolor='black')
plt.hist(absolute_errors_improved, bins=bins, alpha=0.5, label='Improved Absolute Error', color='green', edgecolor='black')

plt.xlabel('Absolute Error')
plt.ylabel('Frequency')
plt.title('Comparison of Absolute Errors: Baseline vs Improved Predictor')
plt.xticks(range(5))  # Set x-ticks to align with the error levels (0 to 4)
plt.legend()
plt.show()
